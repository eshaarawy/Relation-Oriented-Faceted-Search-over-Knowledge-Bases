{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5942,
     "status": "ok",
     "timestamp": 1598602396363,
     "user": {
      "displayName": "Taro Aso",
      "photoUrl": "",
      "userId": "14621805940381040565"
     },
     "user_tz": -540
    },
    "id": "ijivQYrhHVKJ",
    "outputId": "f2c659e3-190b-4855-dcca-735a4f65d9e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 15:18:08.665992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 15:18:09.360881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-05 15:18:09.360928: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-05 15:18:12.197523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-05 15:18:12.197879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-05 15:18:12.197899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/M1_INFO_uga/SEMESTRE_2/TER_Tsukuba/candecomp_parafac/cpdecomposition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/tensorD/tensorD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1598602631681,
     "user": {
      "displayName": "Taro Aso",
      "photoUrl": "",
      "userId": "14621805940381040565"
     },
     "user_tz": -540
    },
    "id": "dZtkus1RiZH9",
    "outputId": "66976191-1793-49b9-beb8-3c2ca67d68e7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonage dans 'tensorD'...\n",
      "remote: Enumerating objects: 1877, done.\u001b[K\n",
      "remote: Total 1877 (delta 0), reused 0 (delta 0), pack-reused 1877\u001b[K\n",
      "Réception d'objets: 100% (1877/1877), 12.16 Mio | 631.00 Kio/s, fait.\n",
      "Résolution des deltas: 100% (1202/1202), fait.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Large-Scale-Tensor-Decomposition/tensorD.git\n",
    "#!pip install git+https://github.com/Large-Scale-Tensor-Decomposition/tensorD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 963,
     "status": "error",
     "timestamp": 1598602752815,
     "user": {
      "displayName": "Taro Aso",
      "photoUrl": "",
      "userId": "14621805940381040565"
     },
     "user_tz": -540
    },
    "id": "3s34n4g3ERtU",
    "outputId": "6c66a1ad-e413-40d6-daa4-f07e6fce4da2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorD.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# import necessary packages\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactorization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menv\u001b[39;00m \u001b[39mimport\u001b[39;00m Environment\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataproc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprovider\u001b[39;00m \u001b[39mimport\u001b[39;00m Provider\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactorization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcp\u001b[39;00m \u001b[39mimport\u001b[39;00m CP_ALS\n",
      "File \u001b[0;32m~/Documents/M1_INFO_uga/SEMESTRE_2/TER_Tsukuba/candecomp_parafac/cpdecomposition/tensorD/tensorD/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Created by ay27 at 17/1/11\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mloss\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfactorization\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdataproc\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/M1_INFO_uga/SEMESTRE_2/TER_Tsukuba/candecomp_parafac/cpdecomposition/tensorD/tensorD/loss.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Created by ay27 at 17/2/23\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorD\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39ml2\u001b[39m(f, h):\n\u001b[1;32m      7\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m    L2 norm\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorD.base'"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "from tensorD.tensorD.factorization.env import Environment\n",
    "from tensorD.tensorD.dataproc.provider import Provider\n",
    "from tensorD.tensorD.factorization.cp import CP_ALS\n",
    "import tensorD.tensorD.demo.DataGenerator as dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4hzIbdABbav"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# use synthetic_data_cp to generate a random tensor with shape of 40x40x40\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdg\u001b[49m\u001b[38;5;241m.\u001b[39msynthetic_data_cp([\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m40\u001b[39m], \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m data_provider \u001b[38;5;241m=\u001b[39m Provider()\n\u001b[1;32m      4\u001b[0m data_provider\u001b[38;5;241m.\u001b[39mfull_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: X\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dg' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# use synthetic_data_cp to generate a random tensor with shape of 40x40x40\n",
    "X = dg.synthetic_data_cp([40, 40, 40], 10)\n",
    "data_provider = Provider()\n",
    "data_provider.full_tensor = lambda: X\n",
    "env = Environment(data_provider, summary_path='/tmp/cp_demo_' + '30')\n",
    "cp = CP_ALS(env)\n",
    "# set rank=10 for decomposition\n",
    "args = CP_ALS.CP_Args(rank=10, validation_internal=1)\n",
    "# build decomposition model with arguments\n",
    "cp.build_model(args)\n",
    "# train decomposition model, set the max iteration as 100\n",
    "cp.train(100)\n",
    "# obtain factor matrices from trained model\n",
    "factor_matrices = cp.factors\n",
    "for matrix in factor_matrices:\n",
    "    print(matrix)\n",
    "# obtain scaling vector from trained model\n",
    "lambdas = cp.lambdas\n",
    "print(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "trial_tensord.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
